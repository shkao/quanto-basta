 So this is the second part in this tutorial series. Last video, we removed ambient RNA, doublets, and low quality cells. This time, we're going to focus on integrating the samples together and annotating the cell types. So we're going to start off in a new Jupyter notebook in the same working environment as we had going previously. We're going to import some of the same modules we used last time. We're going to be reusing a lot of these. So we're going to install CellTypist, which we'll use to transfer labels from a reference data set, SEVI Tools, which we'll use for both label transfer and integration, and then just a few other things. You'll see why we need those later. I'm also going to quiet these warnings so we don't get a lot of spam to the Jupyter notebook. And then we can import CellTypist. And I'm also going to use one of their default models. So I'm going to import models as well. So we can look at the models I have already downloaded. If you're running this for the first time, it might take a second to download some of these. But they do have a lot of prepackaged models that come along with this module. For immune cells, they have two really good models with a lot of different immune cell types. And one of them is this immune all low. There's a high, I think, somewhere. But basically, this one has higher resolution, so finer groupings of cell types. So we're going to be using this one. But we're also going to be using a couple custom reference data sets just because our cells are in the context of AML. And this data set might not cover those cell types completely. So for the reference data sets, I chose two different data sets here. One is this collection of bone marrow samples from 16 AML patients and five healthy donors. And the other data set is a combination of this mixed phenotype Q leukemia and some healthy developmental samples. In both cases, you can just go download the links here. I already have them downloaded, so I'm just going to stop that. But just make sure to move them to their own directory and untar them. In this case, I have them in this ref data directory. For our first reference data set, they actually have these. They're just tab delimited text files of the matrices and the corresponding annotation files. So for each sample, we need to load in the matrix file, and we need to add the annotations to them. In this case, out of the data they deposited, I'm only interested in these DEM files. So I can filter out this list to only get the DEM files. And then I'm just going to loop over this list of DEM files. And then our output is going to be this R data's list. I'm going to get a base name from each of these because we also need that annotation file. So I'm going to split it the period and get the first item. So it's going to be this part. I'm going to split at the underscore and get the second part. So it's going to be this chunk here because this is coming from base name, not the whole string. And then this looks like a lot. But basically, I'm just fishing out the right annotation file based on the sample name. I'm listing all the files with annotation. And then based on the sample name, I'm getting the corresponding annotation. And then I'll use scanp to read in the matrix. And in this case, it has to be transposed. Then I'm reading in the annotation file with pandas and getting the only column I really care about, which is cell type. Then I'm merging the data together. So in the observation data frame, I'm combining those annotations. And then I'm just going to add a unique ID to each sample, which is just the base name. After that, we can just append that temporary data to our list of reference datas. So to load in those 43 samples only took about a minute. Now we're going to make a concatenated scanp object just called rdata, which is just a concatenation of all those rdata from the list. So we have our reference dataset now with 41,000 cells. And we can look at the different cell types. And we're going to use this now to make our custom cell typist model. So we're just going to do some basic filtering. And I'm also under the assumption here that they did reprocessing on these for they uploaded the data. But anyway, here we have to, based on the cell typist recommendations, we have to normalize our data to 10,000 counts per cell. This isn't a widely done practice anymore for normalizing cells. And we'll get into a better method in a little while. But for cell typist, you still need to do this. And then we'll log 1p the data as well. So we have our normalized log 1p reference data. We can then train our reference model. We're passing this normalized reference data. We're passing cell type, which is just the, if we look at the observation column or data frame, we have cell type column, which we need to pass here. Number of jobs, just how many CPUs you can use. This doesn't take too long. Use SGD. We're setting that to false. It's supposed to be a little more accurate if you set this to false. And then we're telling it to select the features for us. So it's actually going to run the model twice. The first time it actually narrows down the features to use. And we're just going to pick the 300 top genes. So this will run for about 100 seconds or so. And we got an error. What is this? So input contains NaN. So it's yelling at me because there's probably Na values in cell type. So we can actually pull through those out. So we're getting rid of everything that is Na here. So we had 41.090. Now we have 40.307. So yeah, there were a couple hundred Na cells there. All right, so that didn't take too long. But I will save the model because I don't want to have to rerun this. The default cell typist model directory is in your home directory. It's this hidden directory. Point to your home directory, .celltypist. In this case, I'm giving it the very descriptive name called ref. So if we look at the files from the second ref data set, you'll notice something here. These are not in the same format as the previous ones. These are actually saved as RDS objects. So how the heck are we going to open these? Actually, there are some pretty nice tools that we can actually transfer these RDS objects right into Scampi objects right here in our notebook. We don't have to do any weird conversion. And to do this, we're going to use this and data to ri. I'm pretty sure we have to install this still. But let's go ahead and import this. And then we have to activate it like this. So this is going to run R in the background. And in that R environment is where you need to install these different dependencies. The easiest way I found is just to do it from here. So it makes sure that everything is in the right environment. And then if you get prompted, just make sure to hit yes or no. But anyway, when they're installed, we can load them in like you would in R. And to actually get the annotated counts, so the counts that they made available on Geo were actually just the raw counts. So they have annotated counts. Had to follow a link from their paper to their GitHub. And then from their GitHub, I could get these links. And the one that was actually annotated from leukemia patients, the annotations were pretty broad. They weren't actually based on cell type. I don't know if there's something missing. But the ones from the healthy hematopoiesis actually have the cell type labels. We just want this one. The others are different modalities. So to open up that RDS file that we downloaded, all we have to do is read RDS. And this is a range summarize experiment. We're creating a SIROT object from this range summarize experiment, getting the counts and then the metadata. And then we need it as a single cell experiment object. So we're taking the SIROT object and then converting it as a single cell experiment object. And then importantly in here, we make sure to specify that our output is going to be the healthy object. So we have our scanp object now. And it's got 35,000 cells. And if we look at the bio classification column, these are our cell types. So making the model is going to be very similar. We're going to normalize each cell to 10,000 counts, log one P that. And then we're going to make the model. In this case, I'm just calling it ref two. And we have to pass the right column for the cell classifications, which is bio classification. And the rest is going to be the same. And once that's done, we'll save it just like we saved the other model, in this case, ref two. And if we go and look at our memory usage, we're already using 26 gigs of memory and we haven't even loaded in our data. So since we've saved these models, we don't actually need to hold their data in memory. We could go around and just delete all the different variables, but I think the easiest way to do it is just go to kernel and restart. But back down to six gigs now. So we cleared 20 gigs of memory. And we can go reload some of these modules and then just go back to where we just left off. And I'm going to load the three models we're going to use now. And that's our first ref model. We don't have to pass the full path because it's going to look in that default directory anyways. Our ref two model, and then this model, I'm just calling it model low. It's this immune all low. And now we actually have to make our function that takes our input cells from our query data set and transfers the labels from these reference models onto it. So we're just going to call this predict cells, filtering out some of the genes that aren't expressed. So we have to do the target sum of 10,000 genes per cell or 10,000 counts per cell again. So we're not actually going to do this to our data. Well, we are doing it to our data, but we're not going to save normalization. We're going to keep everything as raw counts for right now. And then we log one P that, and then we need to densify the counts. So this wouldn't work very well if your data set was a large data set. We're going to be doing this on each individual sample. It's not really going to be feasible for us to do 300,000 cells converted to a sparse or a dense matrix. So we make predictions using cell typist annotate. We pass a data object, which we just brought into this function. We're specifying the model, in this case, model low. And then I'm going to use majority voting false. And then to get the results from this, the easiest way is just to create this new and data object. But within that and data object, there's going to be two columns we're interested in, and that's this predicted labels column. So we're taking it from this predictions, a data, and putting it on our a data object. And then we're also going to get the confidence score. Cell typist is a logistic regression, and using the output from the logistic regression, you can actually calculate a probability score from zero to one. So we're just taking those two columns, putting them on our a data. This is just for model low. I'm just going to write these three times. So I just have this for each of the different models, our model low, our ref model, and our ref two model. And low label, low score, ref label, ref score, and then ref two label. I'm only going to return the observations. So this is going to return a data frame where each row is just equal to one cell. Okay, so now we can actually load in our a data objects. So these are the pre-processed objects we made last time. They're saved in the PPA data directory. I'm just looping over every item in that directory, opening them up and with scanP in this list. So if we look at a data, it's just our 75 different samples. And we're going to pass every and data object to this prediction function we just made above. Importantly, we're going to pass copy. It's going to make a copy of each item before it passes it so that it doesn't normalize the counts. Like I said, we're not going to save the normalized counts that happen in this function. We're going to keep everything as raw. So we need to pass copy. So it'll take a little bit of time, a few seconds for each sample, 75 samples. Okay, so we have our predictions. This is just a big list of Panda's data frames. And we're just going to concatenate those with Panda's concatenate. And I really only care about a few of these columns, so I'm just grabbing them like this. So now we have our predictions data frame. And then we can also combine our A data's now into one A data object. So we have our A data object with 300,000 cells and 33,000 genes. And you can save the predictions to a CSV. Actually, so I'm going to show one more method of label transfer. It's going to be a little redundant, but I'm going to use those two reference data sets with SEVI to transfer both labels from both data sets at the same time. And to do that, we need to add a cell type column to our A data right now, and data.obs. Just has a bunch of different QC metrics that we added in the previous video. But no cell type or anything. So we're adding cell type column and populating it with unknown. And then I'm also adding a batch. It's not really a batch column for this data set, but we're going to combine these three data sets into one, the two references and this data set. So I need a way to easily differentiate between the two. So we're just going to call that AML. And actually, now that I just realized we restarted the notebook, so we actually have to get those open again. And in this sense, we did have to restart them because we need the raw counts here, not the normalized counts. So I'm just going to scroll all the way back up to our data. We're going to load that in. Once that's loaded, we'll concatenate them. And we'll filter genes, but we're not going to run normalized total or log 1P. We need the raw counts. We do still need to remove the NAs. And then we do need to load in this second data set again. We don't need to install these a second time. We need to load them and we need to load this. So we have a raw counts now from both our reference data sets and our query data set or the data set we're working with. I'll just put this note here. We need to reload them because they were normalized earlier. And then we need to add the same columns to both the reference data sets. So we need the cell type column and we need a batch column for our healthy or the Ref2Data object. We just called it healthy earlier. We're adding the cell type. And in this case, it's the bio classification column. So we're just making a copy of that column and calling it cell type instead. And we're adding a batch column and calling it Ref2. We're also making a sample column. So if we look at healthy obs, it doesn't have a sample column, but it has the sample information and the barcodes. So we're just making an extra sample column for when we train our SCBI model. And then our data already has a cell type column. We're adding batch as Ref. And then we're copying the ID column and calling that copy sample so that they all have the same columns here. And then we can just call this whatever. I'm gonna call it Dater. And it's just a concatenation of our three data objects. So our query data and then our two reference data sets. We have ourselves our sample ID, cell type, which is unknown or our query data set. And then just three different values for batch, depending on what data set it came from. And we're going to get the top variable genes from this using Serot version three, because we're using raw counts. We're just gonna get the top 2000. And we're gonna use batch as the batch key and just subset that because we don't actually need the genes from this data object. We're not gonna use it for analysis, just for label transfer. All right, so now we have 370,000 cells and 2000 variable genes. Just to double check to make sure there's no NA in the cell type column. I think we removed those earlier, but this should be the same length as that it is. And then we can import SCVI. So this is gonna be a very quick and dirty way to set up an SCVI model. This is just for label transfer. You can theoretically do what we're gonna do in a few minutes here. It's just gonna add on some time. I'm not gonna set max epochs here though. We're training this VAE model using SCVI and we're accounting for batch and sample. Don't worry, if you don't have a GPU, the CPU is just gonna take a little while longer. But we only have 2000 features. So usually this is only gonna take a few minutes. All right, so once that's done, we have our trained VAE model. We can actually set up this supervised model for transferring the labels. So we're passing our VAE, our AN data, and this is why I had to add unknown earlier because now we're saying our unlabeled category is the unknown, which is just the string in this case that is in that column in the data frame. And our column with the cells is cell type. This doesn't matter that much. It'll do a good job with 10, which is I think the default, but the end samples per label, this makes a big difference. If you have huge disparities in the number of cells between the query and the reference for any given cell type, that can really affect the fidelity of the transfer. So you need to sub-sample this or to down-sample it so that it keeps the number of cells in both the query and the transfer similar. And again, this will take a few minutes, nothing too crazy. All right, so once that's done, we actually only need two things from it. One is this prediction. So this is just gonna return a list the same length as our data object. And then we can do the same thing, but we can pass soft equals true. And when we do that, we get a data frame that's the same length as our data object, but it has a column for each of the cell types and the probability of that classification. And in this case, it's just the probability based on the model. So it should all add up to one, and we'll get into why that's important in a little bit. But if we take the max here, we can just get the max value for the corresponding prediction here. So we're just gonna add this as a new column and data. And likewise, we'll add this prediction score as well. And then we'll filter data down so it's only our query data set. So now this should be identical in size to our A data object, but we can go ahead and just concatenate that onto our A data object. So this will just add two columns onto our A data, and we'll just overwrite A data ops. And then we'll do the same thing with predictions. So we're just gonna merge this predictions data frame onto A data's ops. All right, so we have our A data object with our transferred labels. These aren't gonna be our final labels. We actually have to manually verify some of these, but let's go ahead and save this now so that we can clear our memory. And if we do have to restart the notebook for any reason, we can just load the A data right away. So we're just gonna write that as an H5AB. And just call it whatever unintegrated H5AB. All right, so let's restart the notebook. So we're gonna have to reload some of these and I'll put the CPI up here now instead of having to find it in the middle of the notebook. We should be done with cell typist now. So let's just go ahead and load that A data. All right, so we have our A data object, but this is unintegrated. We don't have any integration embedding. All we've done so far is put the data into one object. So we're actually gonna use SEVI to get the embeddings to actually integrate the data together. We could use default SEVI model parameters, but we're not gonna do that. We're actually going to use hyper parameter tuning to make the model as good as possible. And those two random packages that I installed earlier, I didn't say why, is that model tuner and array, which we need to actually tune these hyper parameters. We're gonna do something similar to what we did earlier, but now this model is gonna be well fine tuned. First, let's filter out some of these lowly expressed genes. And now we're down to 21,000 genes. Since we have 300,000 cells, we're not gonna filter this down any further. If you only had 10,000 cells, maybe for this integration step, you would only use 2,000 genes. And in that case, it could be the 2,000 most variable genes. And then we need to define our search space. But before we do that, let's just define this model CLS, which we're gonna use to do our hyper parameter tuning. Pass sample as a categorical covariate key. In this case, we don't really have a batch. So there's no batch key. And then as the continuous covariate keys, we're using those QC data we put on earlier. In this case, percent count mitochondrial and percent count ribosomal. So we're just gonna initialize this. But we can look at the tuner info now. So this is a list of all the different hyper parameters in our model that we can change. So typically the SCBI default does a pretty good job, but we have the ability to tune these hyper parameters to make it do an even better job. And we're not gonna tune all of these. A lot of them aren't gonna make that big of a difference. And then you just have so many combinations that the tuning becomes unfeasible. I'm gonna define a pretty simple search space here. The more you include in your search space, the longer really you have to train it for because there's more combinations that it needs to test. But we're gonna test four different number of hidden units. We're gonna also test various dimensions of the latent space, the number of layers in the model, the learning rate, and the different, two different distributions. So negative binomial and zero inflated negative binomial. So now that we set the search space, we can actually run the hyper tuning. We're passing validation loss, which is under here as the variable metric. I have to specify GPU here if I do have a GPU, otherwise it uses my CPUs. So if you do have a GPU, just specify it here. We're passing our search space, the number of samples. So how many iterations, how many combinations of this search space will it actually test? The higher this number, theoretically, the more accurate your hyper tuning will be, but it's gonna take longer. And then the same thing for your max epoch. So every time it runs a combination of hyper parameters, how many epochs will it train that model out to? Later, when we actually train the model, we're gonna set this to like 200. So you could change it here to make it a little bigger, but it should have a pretty good idea in those first 20. This will take a couple of hours though, because we're basically training the model a hundred different times. But basically this is what the output will look like. All the different trials and then the validation loss. So the lower the number, the better. So basically we just find the lowest one here, and then we get these different hyper parameters from it. And instead of finding it in this data frame, you can make a loop like this to go through every single one of the results. And in the end, it'll give you the best result or the index for the best result. And then you can take that index, pass it to your results and get the best result here. All right, so I just transferred that back to our current notebook. And so we have the hyper parameters that we wanna use here. So we're gonna set up our ADATA with SEVI setup and data. Again, we're gonna be using sample percent mitochondrial and sample percent ribosomal, same as our tuning model. But then when we actually run our model, we need to pass these different hyper parameters. So we're gonna initialize these. We still though need to specify learning rate. We're gonna make a little dictionary that's just learning rate and then the learning rate we wanna use. And then we can do our model training. So by default with the model this size, it's only gonna do probably like 20 or 30 epochs, but I'm setting it at 200 and early stopping is true. So if it doesn't improve after a certain number of epochs, it'll just stop early. And then I just have to pass that keyword dictionary. All right, so I just canceled early because I didn't wanna wait 50 minutes. I actually already ran it. So I'm just gonna load it in as model. I'll show you how to save it in a second. To save it, we could just do model.save and I'm calling it the model. This is the directory it's gonna save it in. Already have it, so I'm not gonna run it again. And then we can load it like that. But let's actually look how the training did. We can get our minimum reconstruction loss. So we have model history, which just has some of the training history. It's got a lot of different stuff. But basically we're gonna take the reconstruction loss for the validation and we get the minimum 5,248. And then we can plot the training and validation loss over time. And I'm just passing y as a line just to see the minimum. So here's our training and validation loss curves. This is kind of what you would expect. It looks like it could have stopped probably a lot sooner, like at 75 epochs. But the main takeaway here is that your validation decreases and you don't see anything funky. If it starts going up and down later on, that means you might be overfitting. And if it hasn't plateaued yet, that means you could increase the number of epochs to maybe even get a better model. But this one looks like it's as good as it's gonna get. And we don't see too much variation or an increase at the end, which would indicate overfitting. I do recommend saving your ADATA too, just so that it's in agreement with your model. All right, so what we really need from model, so there's different things you can do with an SCVI model. We're really only gonna be doing one thing and that's using it as an integration method. So we need the embeddings. And in this case, we're getting the latent representation from our model, which we'll then use to find neighbors and do the clustering. And that just adds our embeddings to our ADATA. Now we can use these to calculate the neighbors. You just have to specify this new slot or by default, it would look for PCs. Once we have the neighbors calculated, we can do clustering. In this case, I'm going to overcluster it. I'm using a very high resolution here. We're just gonna use this overclustering as a heuristic to help us label. If the resolution was too low, some of these dissimilar cell types might be included in the same cluster. So when we manually verify, sometimes it's better to overcluster and put similar clusters together as a similar annotation than it is to label a cluster that is actually a mix of different cell types as one cell type. This is gonna take like 10 to 15 minutes. Okay, so before I even run UMAP, I want to point out a couple things. Some people do use UMAPs inappropriately. I'll just quickly use this analogy to explain what the issue is. So think of the distance between two points on a map. Let's say you're flying between, I don't know, somewhere in North America to Europe. You would think looking at a map that the shortest distance would be this straight line, but this map actually represents a sphere. The world isn't flat like some people might believe. So the actual shortest distance between these two points is something like this. So if you think about the underlying structure of your single cell data as the globe and a UMAP as this 2D map, just be aware that the UMAP can distort the distances between the data and it's not a one-to-one representation of the distance between data points. So just because two cells are close together on the UMAP or far apart, that doesn't always mean that they're more similar or more distant. Some people might say that they're completely useless, but a lot of other people might argue that there's still a lot of use for them. At the end of the day, a visualization is a way for a person to understand a lot of data at once. I personally, for some metrics, would rather look at a UMAP than a bar plot with 60 different bars on it or something like that. So now that I have that out of the way, I'll actually run UMAP on our data. And both UMAP and Leiden are based on our integrated embeddings because they both rely on neighbors, which we calculated with XSCVI. So now we actually do need to normalize and scale the data for some functions, but we want to keep the raw data. This is important. Always keep the raw data untouched in a different layer because that's what we're actually gonna use down the line for differential expression and some other different analyses. So we're gonna make a new layer called counts and make sure it's a copy of X just so that when you change X, it doesn't change that as well. And now we're gonna normalize it the right way. Like I said, normalizing yourself to 10,000 counts per cell is not the right way to do it. It's kind of ironic that the right way to do it is actually the default method for ScanP based on this recent Nature Methods paper that was published last year. They compared a bunch of different methods for transformation. And if we look at the best performing one, people have published like 30 different ways to do this. A lot of people used to recommend SCTransform. People started using like Pearson residuals, all these different methods to scale and transform new data. And at the end of the day, it kind of did a full circle and came back to one of the original ways, which is basically just using the scaling factor and doing log one P on it. Almost identical to what the default method from ScanPPP is. And then we can do our log one P just like we did before. So super simple and it's nice that this is verified by that recent review. Just save temporary H5AD file that you can load again if something goes wrong. All right, first, just to make it a little easier to see on a plot, I'm going to group our AND data, our observations by that over cluster column. And then I'm going to get the low label, which is that one immune data set we use to transfer the labels from. And then I'm going to get the label that occurs the most in that over cluster and make a new column called low major. If I didn't do that, there would be some more cells that show up here and it would be harder to match up the colors to the actual clusters. You can do the same thing with our predicted column, which in this case came from our SEVI transfer. And we can do the same thing with our ref label. And then importantly, we can look at the transfer scores here or the probabilities or the confidence scores calculated by cell typist. We can see that some of these clusters seem to be labeled well, especially if we look up, this cluster appears to be T cells, and we can see that the T cell clusters have high confidence. Some of these other clusters, especially this big grouping and here seems to have lower confidence scores. And this is a great time to add a huge caveat here when using any kind of label transfer. I wanted to show a quick example of what happens if you use the wrong reference data. So whenever you're doing this automated transfer, the reference and the query data have to be correspondence. So every cell type in the query should be represented by a cell type in the reference. If it's not that way, you really have to go and manually check a lot of the clusters. So in this case, for this example, I'm downloading just the type of more CNS, which has different tissues. I'm making the reference data set from lung and the query data set from heart. So they have very different cell types. There might be like very little overlap of like some circulating immune cells or something, but the cell types are very different. And then I'm just doing the label transfer like we showed earlier, two different ways, one with SEVI and the other with cell typist, just to show that it's not just an issue with one transfer algorithm. So I do the SEVI label transfer that we did earlier. If we look at the actual cell types, in this case, this is the query data set, which is that heart data. And these are the actual cell types. So orange, cardiomyocytes, red, endothelial cells. If we look at the predicted, these are completely different, right? So these cardiomyocytes are now labeled CD4 positive cells. It's not like it's a mix of cells. They're almost all labeled CD4 positive cells. But when you look at the transfer score, like I said, each score adds up to one. And these CD4 positive cells that are actually cardiomyocytes still have a high transfer score. And then we can do the same thing with cell typist, right? So we make our custom model using the lung reference and we map these to the data. So here is the heart data again, and we see a similar thing, completely apparent mappings. It just picks a cell type that might be the most similar and that whole cell type gets labeled as that. So something that should be a cardiomyocyte is now this mix of CD4 and CD8 positive cells. So completely apparent mapping and high confidence scores. So even for cell typist, which the confidence score theoretically is more informative than the score from SEVI, you can still get these apparently high transfer scores or confidence scores, even though these cell types are completely wrong. So again, it is very, very important when you're doing automated transfer or any transfer to make sure that the cell types in the query dataset in your data are represented in the reference data. And with that out of the way, this isn't the case for the reference datasets I had. It was really hard to find a well annotated or any annotated dataset for AML. There were some datasets I wanted to use, but then the authors didn't upload the annotations. The data weren't available. So I was stuck with these references. And then I also used the pre-built reference just to show that. And because they have a lot of nuanced, different immune cell types. But at the end of the day, we're still going to have to go and verify these clusters. We can use the transfer data to help inform our manual labeling, but we're not going to take it as is. So we're going to label each of the over clusters individually. And we can plot by diagnosis. So remember we have the diagnosis remission and relapse. And here's a really nice trick to randomize the indices so that there's no over plotting. So this mixes up all the colors instead of plotting green on top because it was the last one. So you can really get a sense of where these different populations fall. And you see there's almost no remission cells in here. These are all diagnosis and relapse. So these are probably a lot of AML blasts in here, which is that immature blast type cell that accumulates in AML. When I first picked this dataset, I was like, it's PBMCs, how hard can it be to label? Usually these kind of automatic transfer labels do a really good job for PBMCs. That definitely wasn't the case with this dataset. I actually had to go through the literature to find different markers for these blast cells. So here is just two sources I found. And I just pulled a list of genes from this. Some of these are protein markers that people have come up with over the years for surface markers for like flow cytometry. They might not always be the best for actual RNA expression markers. But some of these I made sure to pick from actual transcriptomic studies of blast cells. So we have this list of genes that are theoretically specific to blast cells. And instead of looking at each gene individually, we can actually get a score for a gene set using this scanVTL scored genes. And we're just gonna call that AML blast score. It'll just add another column to that observation data frame. And then let's see how it overlaps with some of these markers. So these three markers are really well-known markers, transcriptomic markers of these blast cells. So we see these three really overlap with that section earlier. This section that's only in the diagnosis and relapse. We can plot just the blast score if we wanted to. And again, it's really corresponding to that one big section in the middle there. But this is a score, it's not a classification. So obviously the higher the score, the more likely it is a blast cell. But let's see what the distribution of scores looks like in these different clusters. So I'm just gonna make a new small data frame. That's just two columns from our observation data frame, the cluster and the blast score and group by the cluster and get the median. So it's just a data frame with each cluster and their score. And it's a relative score, the score can be negative if we were to plot that. We see that there is a lot of variation and we'll be able to use these scores when we're looking at these individual clusters to get an idea of what the clusters are. And then also those transferred labels will help with our determination. And I'm just going to make a new data frame, which is a combination of the transferred labels and our transferred scores. So there's just gonna be one row for each of the 66 clusters. We have our labels and then the scores just to make that take a little less space. So we're gonna use these data, our blast scores and our mapping results in combination with known marker genes to label these clusters. And to do that, I like to just fill out a dictionary where the keys are gonna be the cluster number and then the values are gonna be the cell type. And you can do something like this where we're just taking all the unique clusters and printing zero through the number of clusters and then just making this dictionary type format here. And I'm just gonna copy this and replace the text here. And then I'll go through and fill this out with the actual cell name. So this is what we'll work through. And save our results in. So let's do a couple of clusters. I'm not gonna show all 66 cause this is literally a couple hours of work. A lot of them are gonna be similar. Some of them might be a little trickier. There are different databases for known cell type markers. For special cell types, you might need to read the literature and find specific markers like I did for the AML blasts. So one good database, even though it kind of spams you with ads every once in a while, is this PangloDB. You can go to search. Oh, look at that. And add, cool. Go to scroll out to exit it. And it's gonna go to search where you can search specific genes that might be a marker gene for your cell type. More useful is this data set cell type markers. And you can go to different cell types like immune. If we go to NK cell, we see that these are the top markers for NK cells. So we'll actually be using this in a second. So let me just copy that. So cluster one, or cluster zero, three methods said NK, one method said CD8. These three were from that logistic regression. And the transfer score is always gonna be higher because the sum of those scores always adds up to one. These aren't always 100% accurate either, like I showed in the bad mapping. But anyways, what's going on with zero? So let's look at our clusters. Zero is this cluster here. If we plot that gene that we got from PangloDB, we see that it does overlap with zero very nicely. And looking at the feature map like this doesn't really give you super objective results. So actually one step before we really start labeling the cells is we're gonna find the marker genes for each one of these clusters. So we're grouping by over cluster and then turning this into a data frame. A note here that this is a really quick and dirty way to do differential expression. If we were doing actual differential expression, we wouldn't do it this way, but it's accurate enough for finding marker genes. All right, anyway, that's done. I'm gonna reverse in this output. But now that we have marks, we have the data frame with the cluster, the gene name, the statistic, the log-volt chain, et cetera. So if we wanna go back down to here and look at what clusters are actually expressing this NKG7, we can do that and look at the top ones. And like we expect, cluster zero is the highest expressing one. These might just be NK clusters that are smaller that we annotate later. So if it wasn't the top one, don't really worry, as long as the log-volt change is positive and high. And then let me just show you one more thing before we move on to another cluster. I know this is an NK cluster, so let's see what our AML blast score looks like. And again, this was just this one column data frame. So what is AML blast score specifically for zero, cluster zero? So negative 0.13. And if we look at that plot of all the different scores, we at least in this case think they're NK cells, so we wouldn't expect a high AML blast score. So for zero, we're gonna go ahead and call it an NK cell. We're just gonna keep it simple with one classification for NK cells. All right, so let's look at cluster one now. We have HSC, MPP, are progenitor cells that shouldn't be floating around in your blood, and they have low transfer score because the AML blasts weren't in the reference data sets. I'll show you another little trick for finding where clusters are if you have like a bunch of different cell types and can figure it out. Basically plotting two different U-maps on top of each other. The first one is just a light gray map of everything, and then the second one is filtered based on this cluster. And here's cluster one. And then let's look at the AML blast score for one, and it's positive, almost 0.2, which relative to everything else is pretty high. So it's very likely based on multiple lines of evidence that this is an AML blast. So I'll just call this AML blast. So let's go to cluster two. It's falling in what we earlier could tell as probably T cells. If we look at the results from the mapping, we got T cells, T cells, T cells, T cells, and they're all, I will differentiate between cytotoxic and helper T cells, so CD8 versus CD4 positive cells. In this case, CD4 positive is helper cells, so they all correspond to CD4 helper cells. And if we look at this, let's just do CD4. And CD8, which is CD8A. There are some cells over here, we don't care about them expressing CD4, it's just a way to tell apart different T cells. So yeah, so this section over here is higher for CD4. This section over here is higher for CD8. And this seems to mostly fall within this CD4 section. So these are definitely T helper cells based on multiple lines of evidence. And curiosity, let's see how the AML blast score looks. And it's around zero, it's negative, so good. Three, it's gonna be the same thing without going through all the different lines of evidence. Three is also a T helper cell. Four turns out to be another AML blast population. So we can start moving through this instead of looking at all of them just to make it a little easier to look at. So five is a new population. So all four agree that it's a B cell. If we wanted to look at a marker gene for B cell, go to B cells and let's find something like CD19. We go back here. Where is it? There is our B cell population or putative B cell population. Can look at CD19. Yeah, CD19 is highly expressive over here. We could check couple markers. Usually that's a better thing to do than checking just one. PXK is not that great. So not every one you find here has to be there, but it's just, you know, the more you find that correspond to these high marker genes or known marker genes is a good thing. Okay, there we go. That one's really high. And then we can look at something like CD19 and we see that five, it's not the top one, but it's very significant. It's very highly expressed. And then again, if we look at this, it's negative or around zero. So we know five is a B cell. All right, on to six, which is another cell type. So six in this case, classical monocyte, monocyte, CD14, CD14. So they all agree that it's a classical monocyte, not the highest transfer scores, but we can double check that. So here's six. If we remember from the diagnosis plot, so six does fall in the remission area as well. So there are remission cells in cluster six. So there's one line of evidence. We know that this cell population exists in remission. Get markers here like YZ or CD14. And CD14 is highly expressed in the same area, as you express in that cluster. Well, it's not the top several again, because a lot of these are myeloid cells. So let's see if it's the top 10. And it is, so three log fold change, very high P value, likely a monocyte, but importantly, because there is overlap, let's see how it does for the specificity of AML blast genes. And even though it has a lot of overlap with these other myeloid type markers, our AML blast specific markers is still negative. So this score is very helpful for this data set. And depending on your data set, you can create a score like this for different cell types that you're interested in. So six is most likely a classical monocyte. I'm going to skip through some of these that are redundant and similar to ones we've already done. Nine is our first little bit of a challenge here, but it's an easy challenge, because usually T cells are pretty easy to annotate. The one reference data set says it's a naive helper cell. So CD4 positive, this reference doesn't really help us, it's just annotated T. These two say it's CD8 positive cell. Based on the transfer scores, these have a much higher transfer score. And this one that says it's a CD positive, this CD8 positive cell has low transfer score. So you might think, okay, it's probably actually a helper cell because this has a higher score. Let's actually double check that. So if we go back down to here, we look at nine, it's on this right-hand side of this big cluster. If we look at CD4 and CD8 again, we see that the CD4 was on the left-hand side, the helper cells, and the CD8, which denotes cytotoxic cells, is on the right side. And this is on the right side. So if we actually look at the expression of CD4 in cluster nine, a lot of things, so let's just skip through it. So cluster nine actually has a very low expression or no expression of CD4, but if we look at CD8, it actually has a very high expression. So again, this is a perfect example of why you can't just take the transferred labels as matter of fact. So nine is actually a CD8 or a cytotoxic lymphocyte, which I'm gonna say is TC. So I'm gonna do cluster 10 and then really start skipping through these. 10 was a surprising one. None of these really correspond to each other, erythrocytes, erythrocytes, metaporetic stem cell, mast cell. Mast cells are usually in the tissues. They're not really down in the blood, but out of all the different rows, this is the only one that was labeled mast cell. So let's actually look at cluster 10. So cluster 10 falls right here, and this section actually had a lower AML blast score, but it is specific to diagnosis and relapse. So my initial thought when I first saw this was it's probably some sort of AML blast, but let's look at the blast score. When we look at the blast score, a low value relative to some of these other scores. So, okay, maybe it's not a blast, but it's specific or AML still in diagnosis and relapse. What actually is expressed in mast cell? So we can go to a mast cell. So let's actually see these top two mast genes, and we see some stick out here with kit, and this one, yes, very strong hit for this mast gene. And if we look at the expression, let's get rid of this. It is by far the cluster with the strongest expression of this mast gene. So yeah, it looks like mast cell, but still it doesn't make sense. So this is when it's sometimes good to verify it in the literature, and I am not at all an oncologist. I really don't know that much about AML, but you can do a little digging and you find out that finding mast cells in patients with AML is actually a marker of bad prognosis. So they do appear in the blood of people with AML. I'm gonna label this mast, but now I'm gonna go a little quicker, and I'm only gonna point out some of these clusters that really stand out. Okay, so 44 wasn't super straightforward, so I'll point this one out. We have various different transferred labels here, monocyte, HSC, monocyte, B cell. When we look at 44, it's this cluster way up here. So this is a good case of, we don't really have any idea of what it is, so we have to kind of take an unbiased look at it. The first place to start usually for doing that is looking at the marker genes. So we can do a marks.group equals 44, and then let's just hit this. So the top 10 genes. So like I said, BangaloreDB has this search function where you can search specific genes. This one's not gonna be that great. This is a pretty common housekeeping gene actually. Kind of cheating here. I know that this is a marker for something, but let's see what happens when I do this. So CSF3R, microglia, it's gonna come from the brain, neutrophils. Okay, that might be found in blood. These may be neutrophils. We're not gonna take this and say they're neutrophils from this. Let's go back to the dataset cell type markers, go down to neutrophils. Look at that, the top marker for neutrophils. The problem here, I think what happens is they're not always sequenced in single cell sequencing. They're pretty fragile. So our reference datasets probably just didn't have any neutrophils in them. So if we look at CSF3R, and let's grab this one then. Top two markers, very clearly in this cluster. Yeah, but at the end of the day, we filled this out. We have a lot of AML blasts and a mix of these other cell types, but just put them in brackets, give them a name. So we have a dictionary now, and then we can map a new column called cell type by mapping our dictionary to our over cluster column. And so if we look at that now, this is what we're left with. If I was an expert in AML, we could probably recluster these AML blasts into subgroups. And then let's just save our results. So ADATA, or H5-AD, and we'll just call it annotated. So now we have our clean annotated data. And importantly, we still have the raw data so that we can do some of these downstream analyses like differential expression, which we're gonna get into next time. So we'll actually start doing the analyses of these data now that they're annotated. So next time, we're gonna do some differential expression and differential cell type abundance analysis.

Source URL: https://www.youtube.com/watch?v=FqG_O12oWR4